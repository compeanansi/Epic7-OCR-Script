{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust the settings in the next cell if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# COMMENT if NOT using windows (i.e., add # before both lines)\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract\"\n",
    "TESSDATA_PREFIX = r\"C:\\Program Files\\Tesseract-OCR\"\n",
    "\n",
    "# UNCOMMENT if using latest tesseract version on mac via 'brew install tesseract'\n",
    "#pytesseract.pytesseract.tesseract_cmd = \"/usr/local/Cellar/tesseract/4.1.1/bin/tesseract\"\n",
    "\n",
    "# Change to False if you always want your actual main stat value\n",
    "assume_max_lv_gear = True\n",
    "\n",
    "# Screenshot path. Only edit this if the screenshot directory is not within the epic7-master folder AND you know what you are doing. Otherwise just move your screenshots to the default folder.\n",
    "sh_path = 'screenshots/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not change anything below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7XiclNuE3fz"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "def process(img):\n",
    "    resize = cv2.resize(img, (0,0), fx=5, fy=5)\n",
    "    gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY) # convert to gray for thresholding + blurring\n",
    "    thresh = cv2.threshold(gray, 70, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    blur = cv2.medianBlur(thresh, 3)\n",
    "    color = cv2.cvtColor(blur, cv2.COLOR_GRAY2RGB) # convert to back to color\n",
    "    img = Image.fromarray(color) # convert from array back into image format\n",
    "    data = image_to_string(img, lang='eng', config='--psm 6') # PSM 6 = assume uniform block of text\n",
    "    data = data.replace('Rina','Ring').replace('Edic','Epic').replace('Enic','Epic') # Fix common OCR errors\n",
    "    return data\n",
    "\n",
    "def iterative_process(img):\n",
    "    # Since level and plus are read off the gear icon, there is a lot of noise\n",
    "    # Thus, we need to use an iterative process to try different thresholding settings to extract a value from them\n",
    "    for low in [81,100,125]:\n",
    "        resize = cv2.resize(img, (0,0), fx=5, fy=5)\n",
    "        gray = cv2.cvtColor(resize, cv2.COLOR_RGB2GRAY) # convert to gray for thresholding + blurring\n",
    "        thresh = cv2.threshold(gray, low, 255, cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)[1]\n",
    "        blur = cv2.medianBlur(thresh, 3)\n",
    "        color = cv2.cvtColor(blur, cv2.COLOR_GRAY2RGB) # convert to back to color\n",
    "        img = Image.fromarray(color) # convert from array back into image format\n",
    "        data = image_to_string(img, lang='eng', config='--psm 7') # PSM 7 = treat as single line of text\n",
    "        data = data.replace('+b','6').replace('>','0') # Fix common OCR errors\n",
    "        if any(i.isdigit() for i in data): return data # If it finds a value it will terminate the loop and return the value\n",
    "    return '1' # return '1' if the OCR fails to recognize the level or plus, so that there are no import errors\n",
    "\n",
    "def stat_converter(stat):\n",
    "    result = '' # default value to return just in case the stat data is bad\n",
    "    if 'attack' in stat.lower():\n",
    "        result = 'Atk'\n",
    "        if '%' in stat: result += 'P'\n",
    "    elif 'health' in stat.lower():\n",
    "        result = 'HP'\n",
    "        if '%' in stat: result += 'P'\n",
    "    elif 'defense' in stat.lower():\n",
    "        result = 'Def'\n",
    "        if '%' in stat: result += 'P'\n",
    "    elif 'speed' in stat.lower():\n",
    "        result = 'Spd'\n",
    "    elif 'chance' in stat.lower():\n",
    "        result = 'CChance'\n",
    "    elif 'damage' in stat.lower():\n",
    "        result = 'CDmg'\n",
    "    elif 'effectiveness' in stat.lower():\n",
    "        result = 'Eff'\n",
    "    elif 'resistance' in stat.lower():\n",
    "        result = 'Res'\n",
    "    return result\n",
    "  \n",
    "\n",
    "def digit_filter(val):\n",
    "    # This attempts to filter out all characters that are not digits\n",
    "    # If there are no digits, then it returns 0\n",
    "    try: return int(''.join(filter(str.isdigit,val)))\n",
    "    except ValueError: return 0\n",
    "\n",
    "def char_filter(val):\n",
    "    # This attempts to filter out all characters that are not letters\n",
    "    # If there are no letters, then it returns ''\n",
    "    try: return ''.join(filter(str.isalpha,val)).capitalize()\n",
    "    except ValueError: return ''\n",
    "\n",
    "def max_stat(data,item):\n",
    "    stat = stat_converter(data)\n",
    "    val = digit_filter(data) # Begin by setting val = actual value so that it gets returned if the rest fails\n",
    "    if item['ability'] < 15: # Only change stats on items where they need to be increased\n",
    "        if item['level'] in range(58,73):\n",
    "            if stat == 'CChance': val = 45\n",
    "            elif stat == 'CDmg': val = 55\n",
    "            elif stat == 'Spd': val = 35\n",
    "            elif item['slot'] == ('Necklace' or 'Ring' or 'Boots'): val = 50\n",
    "            elif stat == 'HP': val = 2295 # Not exactly right, finer-grained scaling\n",
    "            elif stat == 'Def': val = 250 # Not exactly right, finer-grained scaling\n",
    "            elif stat == 'Atk': val = 425 # Not exactly right, finer-grained scaling\n",
    "        elif item['level'] in range(74,86):\n",
    "            if stat == 'CChance': val = 55\n",
    "            elif stat == 'CDmg': val = 65\n",
    "            elif stat == 'Spd': val = 40\n",
    "            elif item['slot'] == ('Necklace' or 'Ring' or 'Boots'): val = 60\n",
    "            elif stat == 'HP': val = 2700 # Not exactly right, finer-grained scaling\n",
    "            elif stat == 'Def': val = 300 # Not exactly right, finer-grained scaling\n",
    "            elif stat == 'Atk': val = 500 # Not exactly right, finer-grained scaling\n",
    "        elif item['level'] in range(87,89):\n",
    "            if stat == 'CChance': val = 60\n",
    "            elif stat == 'CDmg': val = 70\n",
    "            elif stat == 'Spd': val = 45\n",
    "            elif item['slot'] == ('Necklace' or 'Ring' or 'Boots'): val = 65\n",
    "            elif stat == 'HP': val = 2765\n",
    "            elif stat == 'Def': val = 310\n",
    "            elif stat == 'Atk': val = 515\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBct7X1IE3f4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning export process...\n",
      "currently processing screenshots/test_screenshot.png\n",
      "ilvl 88 / enhanced to +15 / slot: Weapon  / rarity: Epic\n",
      "1 exported out of 1 valid items \n",
      "\n",
      "JSON file finished!\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from string import ascii_lowercase, digits\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "# Format the json for the optimizer\n",
    "export = {'processVersion':'1','heroes':[],'items':[]}\n",
    "temp_list = []\n",
    "\n",
    "print('Beginning export process...')\n",
    "\n",
    "# Gather the filenames for all the screenshots. Looks for png, jpg, and jpeg.\n",
    "filenames = glob(sh_path+'*.png')\n",
    "filenames.extend(glob(sh_path+'*.jpg'))\n",
    "filenames.extend(glob(sh_path+'*.jpeg'))\n",
    "\n",
    "did_break = False\n",
    "errors = 0\n",
    "for n,name in enumerate(filenames):\n",
    "    \n",
    "    # The height of the item box changes depending on the length of the item and set descriptions,\n",
    "    # we have to crop the top and bottom info separately in order to ensure the OCR boxes within these areas\n",
    "    # remain in fixed locations. we then process the top and bottom info independently.\n",
    "    \n",
    "    print('currently processing '+name.replace('screenshots\\\\',''))\n",
    "    img = cv2.imread(name)\n",
    "    \n",
    "    # Make sure the screenshot has the proper dimensions\n",
    "    if img.shape[0] != 1080 or img.shape[1] != 2200:\n",
    "        print('ERROR: This screenshot is not 2200x1080!')\n",
    "        print('Please retake the screenshot in Nox or LDPlayer with the internal resolution set to 2200x1080')\n",
    "        did_break = True\n",
    "        break\n",
    "    \n",
    "    # Setup dictionary for the current item\n",
    "    item = {'locked':False,'efficiency':0}\n",
    "    \n",
    "    # Settings for how the boxes are cropped. If the UI changes, these may need to be updated\n",
    "    width = [725,1190] # First = pixel that the gearbox starts at, Second = pixel that the gearbox ends at\n",
    "    top_depth = 160 # This is how many pixels deep the top cropped image will be\n",
    "    bottom_offset = 25 # This is how many pixels we start the bottom box from the divider in the gear screenshot\n",
    "    bottom_depth = 335 # This is how many pixels deep the bottom cropped image will be\n",
    "    \n",
    "    # Coordinates for the various substat types WITHIN the cropped boxes detailed above. If the UI changes, these may need to be updated\n",
    "    # Format = {'stat': [[X1,X2],[Y1,Y2]]} as this marks the coordinates for a mini box for that individual stat\n",
    "    # top_coords are all *relative* to the dimensions of the top box\n",
    "    top_coords = {'type': [[20,60],[172,432]],\n",
    "                  'level': [[19,47],[35,69]],\n",
    "                  'plus': [[2,26],[132,161]]}\n",
    "    # bot_coords are all *relative* to the dimensions of the bottom box\n",
    "    bot_coords = {'main': [[8,70],[65,435]],\n",
    "                  'subs': [[98,255],[25,435]],\n",
    "                  'set': [[280,340],[76,435]]}\n",
    "    \n",
    "    # Top box\n",
    "    temp_top = cv2.imread('e7/top.jpg',0)\n",
    "    a, b, c, max_loc = cv2.minMaxLoc(cv2.matchTemplate(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), temp_top, cv2.TM_CCOEFF_NORMED))\n",
    "    top_box = img[max_loc[1]:max_loc[1]+top_depth,width[0]:width[1]]\n",
    "\n",
    "    # Bottom box\n",
    "    temp_bot = cv2.imread('e7/bottom.jpg',0)\n",
    "    a, b, c, max_loc = cv2.minMaxLoc(cv2.matchTemplate(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), temp_bot, cv2.TM_CCOEFF_NORMED))\n",
    "    bottom_box = img[max_loc[1]+bottom_offset:max_loc[1]+bottom_offset+bottom_depth,width[0]:width[1]]\n",
    "    \n",
    "    # Process stats from the Top box\n",
    "    # Type\n",
    "    data = process(top_box[top_coords['type'][0][0]:top_coords['type'][0][1],top_coords['type'][1][0]:top_coords['type'][1][1]])\n",
    "    split_data = data.split(' ')\n",
    "    item['rarity'] = char_filter(split_data[0])\n",
    "    item['slot'] = char_filter(split_data[1].split('\\n')[0])\n",
    "    if len(item['rarity']) == 0: print('Error: no rarity detected')\n",
    "    if len(item['slot']) == 0: print('Error: no slot detected')\n",
    "    \n",
    "    # Level\n",
    "    data = iterative_process(top_box[top_coords['level'][0][0]:top_coords['level'][0][1],top_coords['level'][1][0]:top_coords['level'][1][1]])\n",
    "    data = data.replace('S','5').replace('B','8').replace('a','8') # Fix common OCR errors\n",
    "    item['level'] = digit_filter(data)\n",
    "    \n",
    "    # Enhance lvl (plus)\n",
    "    data = iterative_process(top_box[top_coords['plus'][0][0]:top_coords['plus'][0][1],top_coords['plus'][1][0]:top_coords['plus'][1][1]])\n",
    "    data = data.replace('S','5').replace('B','8').replace('a','8') # Fix common OCR errors\n",
    "    item['ability'] = digit_filter(data)\n",
    "\n",
    "    print(\"ilvl\", item['level'],\"/ enhanced to +\"+str(item['ability'])+\" / slot:\",item['slot'],\" / rarity:\",item['rarity'])\n",
    "    \n",
    "    # Process stats from Bottom box    \n",
    "    # Main\n",
    "    data = process(bottom_box[bot_coords['main'][0][0]:bot_coords['main'][0][1],bot_coords['main'][1][0]:bot_coords['main'][1][1]])\n",
    "    stat = stat_converter(data)\n",
    "    if assume_max_lv_gear is True: item['mainStat'] = [stat,max_stat(data,item)]\n",
    "    else: item['mainStat'] = [stat,digit_filter(data)]\n",
    "    \n",
    "    # Subs\n",
    "    data = process(bottom_box[bot_coords['subs'][0][0]:bot_coords['subs'][0][1],bot_coords['subs'][1][0]:bot_coords['subs'][1][1]])\n",
    "    for n,entry in enumerate(data.split('\\n')):\n",
    "        if n < 4:\n",
    "            stat = stat_converter(entry)\n",
    "            entry = entry.replace('T','7') # Fix common OCR error\n",
    "            val = digit_filter(entry)\n",
    "            if len(stat) > 0 and val != 0:\n",
    "                item['subStat'+str(n+1)] = [stat,val]\n",
    "    \n",
    "    # Set\n",
    "    data = process(bottom_box[bot_coords['set'][0][0]:bot_coords['set'][0][1],bot_coords['set'][1][0]:bot_coords['set'][1][1]])\n",
    "    data_split = data.split(' Set')\n",
    "    item['set'] = char_filter(data_split[0])\n",
    "    if len(item['set']) == 0: print('Error: no set detected')\n",
    "    \n",
    "    # Check to make sure the item does not already exist in the item dictionary\n",
    "    # Also verifies that it has a valid slot and rarity entry\n",
    "    # If these conditions are met, this assigns the item a unique ID and adds it to the item dictionary for export\n",
    "    if item not in temp_list and len(item['slot']) > 0 and len(item['rarity']) > 0:\n",
    "        temp_list.append(item)\n",
    "        item['id'] = 'jt'+''.join(random.choice(digits+ascii_lowercase) for _ in range(6))\n",
    "        export['items'].append(item)\n",
    "        print(len(export['items']),\"exported out of\",len(filenames)-errors,'valid items \\n')\n",
    "    else:\n",
    "        errors += 1\n",
    "        print('Item not exported because of fatal errors in processing it \\n')\n",
    "\n",
    "# Export dictionary to json for importing into optimizer if everything completed properly\n",
    "if not did_break:\n",
    "    with open('exported_gear.json', 'w') as f: json.dump(export, f)\n",
    "    print('JSON file finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of E7 Gear OCR (Official)",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
